{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils import model_zoo\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import albumentations as A\n",
    "from dataclasses import dataclass\n",
    "import cv2\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tqdm\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _cfg(url='', **kwargs):\n",
    "    return {\n",
    "        'url': url, 'num_classes': 1000, 'input_size': (3, 224, 224), 'pool_size': (7, 7),\n",
    "        'crop_pct': 0.875, 'interpolation': 'bilinear',\n",
    "        'mean': (0.485, 0.456, 0.406), 'std': (0.229, 0.224, 0.225),\n",
    "        'first_conv': 'layer0.conv1', 'classifier': 'last_linear',\n",
    "        **kwargs\n",
    "    }\n",
    "\n",
    "default_cfg = {\n",
    "    'seresnet18':\n",
    "        _cfg(url='https://www.dropbox.com/s/3o3nd8mfhxod7rq/seresnet18-4bb0ce65.pth?dl=1',\n",
    "             interpolation='bicubic')\n",
    "}\n",
    "\n",
    "\n",
    "class AdaptivePool2d(nn.Module):\n",
    "    \"\"\"Selectable global pooling layer with dynamic input kernel size\n",
    "    \"\"\"\n",
    "    def __init__(self, output_size=1, pool_type='avg'):\n",
    "        super(AdaptivePool2d, self).__init__()\n",
    "        self.output_size = output_size\n",
    "        self.pool_type = pool_type\n",
    "        self.pool = nn.AdaptiveAvgPool2d(output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.pool(x)\n",
    "\n",
    "    def feat_mult(self):\n",
    "        return 1\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + ' (' \\\n",
    "               + 'output_size=' + str(self.output_size) \\\n",
    "               + ', pool_type=' + self.pool_type + ')'\n",
    "\n",
    "\n",
    "class SEModule(nn.Module):\n",
    "    def __init__(self, channels, reduction):\n",
    "        super(SEModule, self).__init__()\n",
    "        self.fc1 = nn.Conv2d(\n",
    "            channels, channels // reduction, kernel_size=1, padding=0)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.fc2 = nn.Conv2d(\n",
    "            channels // reduction, channels, kernel_size=1, padding=0)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        module_input = x\n",
    "        x = x.view(x.size(0), x.size(1), -1).mean(-1).view(x.size(0), x.size(1), 1, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return module_input * x\n",
    "\n",
    "\n",
    "class SEResNetBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, groups, reduction, stride=1, downsample=None):\n",
    "        super(SEResNetBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            inplanes, planes, kernel_size=3, padding=1, stride=stride, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            planes, planes, kernel_size=3, padding=1, groups=groups, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.se_module = SEModule(planes, reduction=reduction)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out = self.se_module(out) + residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class SEReSNet(nn.Module):\n",
    "    def __init__(self, block=SEResNetBlock, layers=[2, 2, 2, 2], groups=1, reduction=16,\n",
    "                 in_chans=3, inplanes=64, downsample_kernel_size=1,\n",
    "                 downsample_padding=0, num_classes=1000, global_pool='avg'):\n",
    "        super(SEReSNet, self).__init__()\n",
    "        self.inplanes = inplanes\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        layer0_modules = [\n",
    "            ('conv1', nn.Conv2d(\n",
    "                        in_chans, inplanes, kernel_size=7, stride=2, padding=3, bias=False)),\n",
    "            ('bn1', nn.BatchNorm2d(inplanes)),\n",
    "            ('relu1', nn.ReLU(inplace=True)),\n",
    "            ]\n",
    "        layer0_modules.append(('pool', nn.MaxPool2d(3, stride=2, ceil_mode=True)))\n",
    "        self.layer0 = nn.Sequential(OrderedDict(layer0_modules))\n",
    "        self.layer1 = self._make_layer(\n",
    "            block,\n",
    "            planes=64,\n",
    "            blocks=layers[0],\n",
    "            groups=groups,\n",
    "            reduction=reduction,\n",
    "            downsample_kernel_size=1,\n",
    "            downsample_padding=0\n",
    "        )\n",
    "        self.layer2 = self._make_layer(\n",
    "            block,\n",
    "            planes=128,\n",
    "            blocks=layers[1],\n",
    "            stride=2,\n",
    "            groups=groups,\n",
    "            reduction=reduction,\n",
    "            downsample_kernel_size=downsample_kernel_size,\n",
    "            downsample_padding=downsample_padding\n",
    "        )\n",
    "        self.layer3 = self._make_layer(\n",
    "            block,\n",
    "            planes=256,\n",
    "            blocks=layers[2],\n",
    "            stride=2,\n",
    "            groups=groups,\n",
    "            reduction=reduction,\n",
    "            downsample_kernel_size=downsample_kernel_size,\n",
    "            downsample_padding=downsample_padding\n",
    "        )\n",
    "        self.layer4 = self._make_layer(\n",
    "            block,\n",
    "            planes=512,\n",
    "            blocks=layers[3],\n",
    "            stride=2,\n",
    "            groups=groups,\n",
    "            reduction=reduction,\n",
    "            downsample_kernel_size=downsample_kernel_size,\n",
    "            downsample_padding=downsample_padding\n",
    "        )\n",
    "        self.avg_pool = AdaptivePool2d(pool_type=global_pool)\n",
    "        self.num_features = 512 * block.expansion\n",
    "        self.last_linear = nn.Linear(self.num_features, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            self._weight_init(m)\n",
    "    \n",
    "    def _weight_init(self, m):\n",
    "        if isinstance(m, nn.Conv2d):\n",
    "            nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "        if isinstance(m, nn.BatchNorm2d):\n",
    "            nn.init.constant_(m.weight, 1.)\n",
    "            nn.init.constant_(m.bias, 0.)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, groups, reduction, stride=1,\n",
    "                    downsample_kernel_size=1, downsample_padding=0):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=downsample_kernel_size, stride=stride,\n",
    "                          padding=downsample_padding, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = [block(\n",
    "            self.inplanes, planes, groups, reduction, stride, downsample)]\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, groups, reduction))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def get_classifier(self):\n",
    "        return self.last_linear\n",
    "\n",
    "    def reset_classifier(self, num_classes):\n",
    "        self.num_classes = num_classes\n",
    "        del self.last_linear\n",
    "        if num_classes:\n",
    "            self.last_linear = nn.Linear(self.num_features, num_classes)\n",
    "        else:\n",
    "            self.last_linear = None\n",
    "\n",
    "    def forward_features(self, x, pool=True):\n",
    "        x = self.layer0(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        if pool:\n",
    "            x = self.avg_pool(x)\n",
    "            x = x.view(x.size(0), -1)\n",
    "        return x\n",
    "\n",
    "    def logits(self, x):\n",
    "        x = self.last_linear(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.forward_features(x)\n",
    "        x = self.logits(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def load_pretrained(model, default_cfg, num_classes=1000, in_chans=3, filter_fn=None):\n",
    "    state_dict = model_zoo.load_url(default_cfg['url'])\n",
    "\n",
    "    if in_chans == 1:\n",
    "        conv1_name = default_cfg['first_conv']\n",
    "        print('Converting first conv (%s) from 3 to 1 channel' % conv1_name)\n",
    "        conv1_weight = state_dict[conv1_name + '.weight']\n",
    "        state_dict[conv1_name + '.weight'] = conv1_weight.sum(dim=1, keepdim=True)\n",
    "    elif in_chans != 3:\n",
    "        raise AssertionError(\"Invalid in_chans for pretrained weights\")\n",
    "\n",
    "    strict = True\n",
    "    classifier_name = default_cfg['classifier']\n",
    "\n",
    "    if num_classes != default_cfg['num_classes']:\n",
    "        del state_dict[classifier_name + '.weight']\n",
    "        del state_dict[classifier_name + '.bias']\n",
    "        strict = False\n",
    "\n",
    "    if filter_fn is not None:\n",
    "        state_dict = filter_fn(state_dict)\n",
    "\n",
    "    model.load_state_dict(state_dict, strict=strict)\n",
    "\n",
    "def seresnet18(num_classes=1000, in_chans=3, pretrained=True, **kwargs):\n",
    "    cfg = default_cfg['seresnet18']\n",
    "    model = SEReSNet(SEResNetBlock, [2, 2, 2, 2], groups=1, reduction=16,\n",
    "                  inplanes=64,\n",
    "                  downsample_kernel_size=1, downsample_padding=0,\n",
    "                  num_classes=num_classes, in_chans=in_chans, **kwargs)\n",
    "    model.default_cfg = cfg\n",
    "    if pretrained:\n",
    "        load_pretrained(model, cfg, num_classes, in_chans)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass \n",
    "class config:\n",
    "    dataset_directory = \"\"\n",
    "    best_weights_path = \"best_model.pth\"\n",
    "    train_directory = os.path.join(dataset_directory, \"Train_Data\")\n",
    "    test_directory = os.path.join(dataset_directory, \"Test_Data\")\n",
    "    image_height = 128\n",
    "    image_width = 128\n",
    "    batch_size = 1028\n",
    "    num_epochs = 25\n",
    "    lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = torchvision.models.mobilenet_v3_small(pretrained=False, progress=True)\n",
    "    model.classifier = torch.nn.Sequential(\n",
    "        torch.nn.Linear(in_features=576, out_features=128, bias=True),\n",
    "        torch.nn.Hardswish(),\n",
    "        torch.nn.Dropout(p=0.2, inplace=True),\n",
    "        torch.nn.Linear(in_features=128, out_features=1, bias=True)\n",
    "    )\n",
    "    model.load_state_dict(torch.load(\"mobilenet_model.pth\", map_location=torch.device('cpu')))\n",
    "    return model\n",
    "\n",
    "#model = create_model()\n",
    "model = seresnet18()\n",
    "model.reset_classifier(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [f for f in os.listdir(\"patches_224\") if f != \"labels.csv\"]\n",
    "targets = list(pd.read_csv(\"patches_224/labels.csv\")[\"0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data, train_target, val_target = train_test_split(data, targets, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HistoDataset(torch.utils.data.Dataset):\n",
    "    glob_dir = \"patches_224\"\n",
    "\n",
    "    def __init__(self, img_paths: list = None, labels: list = None, apply_augmentations=True) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.img_paths = img_paths\n",
    "        self.labels = labels\n",
    "        self.augmentations = self.make_augmentations() if apply_augmentations else None\n",
    "    \n",
    "    def make_augmentations(self) -> A.Compose:\n",
    "        return A.Compose([\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.VerticalFlip(p=0.5),\n",
    "            ])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image = np.array(cv2.imread(os.path.join(self.glob_dir, self.img_paths[index])))\n",
    "        if self.augmentations is not None:\n",
    "            image = self.augmentations(image=image)[\"image\"]\n",
    "\n",
    "        label = self.labels[index]\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = HistoDataset(train_data, train_target)\n",
    "val_dataset = HistoDataset(val_data, val_target, apply_augmentations=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        train_dataset,\n",
    "        test_dataset,\n",
    "        num_epochs,\n",
    "        batch_size,\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    ) -> None:\n",
    "\n",
    "        self.num_epochs = num_epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.device = device\n",
    "        \n",
    "        self.model = model\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.optimizer = torch.optim.AdamW(\n",
    "            self.model.parameters(), \n",
    "            lr = config.lr, \n",
    "        )\n",
    "        self.criterion = nn.BCELoss()\n",
    "        \n",
    "        self.best_accuracy = 0\n",
    "        \n",
    "\n",
    "        self.train_dataLoader = torch.utils.data.DataLoader(\n",
    "            train_dataset, \n",
    "            batch_size = batch_size, \n",
    "            collate_fn = self.collate_fn,\n",
    "        )\n",
    "\n",
    "        self.test_dataLoader = torch.utils.data.DataLoader(\n",
    "            test_dataset,\n",
    "            batch_size = config.batch_size,\n",
    "            collate_fn = self.collate_fn,\n",
    "        )\n",
    "        \n",
    "    \n",
    "    def collate_fn(self, batch):\n",
    "        images, labels = [], []\n",
    "        for image, label in batch:\n",
    "            image = torch.tensor(image / 255)\n",
    "            image = image.permute((2, 0, 1)).float()\n",
    "            if image.shape == torch.Size([3, 224, 224]):\n",
    "                images.append(image)\n",
    "\n",
    "                label = torch.tensor([label]).float()\n",
    "                labels.append(label)\n",
    "\n",
    "        images = torch.stack(images).to(self.device)\n",
    "        labels = torch.stack(labels).to(self.device)\n",
    "        return images, labels\n",
    "    \n",
    "    def measure_accuracy(self, outputs, labels, thrershold=0.5):\n",
    "        outputs = (outputs > thrershold).float()\n",
    "        num_correct = (outputs == labels).sum() / len(labels)\n",
    "        return num_correct\n",
    "        \n",
    "    def train_epoch(self, current_epoch):\n",
    "        self.model.train()\n",
    "        \n",
    "        pbar = tqdm.notebook.tqdm(\n",
    "            enumerate(self.train_dataLoader), \n",
    "            total = len(self.train_dataLoader),\n",
    "            desc = f\"Epoch(train) {current_epoch} \"\n",
    "        )\n",
    "        \n",
    "        running_loss = 0\n",
    "        running_accuracy = 0\n",
    "        \n",
    "        for index, (images, labels) in pbar:\n",
    "            outputs = self.model(images)\n",
    "            loss = self.criterion(\n",
    "                self.sigmoid(outputs),\n",
    "                labels,\n",
    "            )\n",
    "            \n",
    "            running_accuracy += self.measure_accuracy(outputs, labels).item()\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            pbar.set_postfix(\n",
    "                dict(\n",
    "                    accuracy = round(running_accuracy/(index + 1), 5),\n",
    "                    loss = round(running_loss/(index + 1), 5)\n",
    "                )\n",
    "            )\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "    \n",
    "    def test_epoch(self, current_epoch):\n",
    "        self.model.eval()\n",
    "        \n",
    "        pbar = tqdm.notebook.tqdm(\n",
    "            enumerate(self.test_dataLoader), \n",
    "            total = len(self.test_dataLoader),\n",
    "            desc = f\"Epoch(test) {current_epoch} \"\n",
    "        )\n",
    "        \n",
    "        running_loss = 0\n",
    "        running_accuracy = 0\n",
    "        \n",
    "        for index, (images, labels) in pbar:\n",
    "            with torch.no_grad():\n",
    "                outputs = self.model(images)\n",
    "\n",
    "            running_loss += self.criterion(\n",
    "                self.sigmoid(outputs),\n",
    "                labels,\n",
    "            ).item()\n",
    "\n",
    "            running_accuracy += self.measure_accuracy(outputs, labels).item()\n",
    "\n",
    "            pbar.set_postfix(\n",
    "                dict(\n",
    "                    accuracy = round(running_accuracy/(index + 1), 5),\n",
    "                    loss = round(running_loss/(index + 1), 5)\n",
    "                )\n",
    "            )\n",
    "        \n",
    "        if running_accuracy / (index + 1) > self.best_accuracy:\n",
    "            self.best_accuracy = running_accuracy / (index + 1)\n",
    "            torch.save(self.model.state_dict(), config.best_weights_path)\n",
    "            print(f\"saved model weights at: {config.best_weights_path}\")\n",
    "\n",
    "        return outputs, labels\n",
    "    \n",
    "    def start(self):\n",
    "        print(f\"Start training using {self.device}\")\n",
    "        self.model.to(self.device)\n",
    "        for epoch in range(self.num_epochs):\n",
    "            self.train_epoch(epoch)\n",
    "            self.test_epoch(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    train_dataset,\n",
    "    val_dataset,\n",
    "    config.num_epochs,\n",
    "    config.batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.start()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
