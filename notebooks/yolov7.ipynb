{"cells":[{"cell_type":"markdown","metadata":{"id":"7fIEw72e8nVj"},"source":["# Introduction"]},{"cell_type":"markdown","metadata":{"id":"0nGvXpl0hPOs"},"source":["Hello from my new project. In this project, I tried to detect masked people and unmasked people using the yolov7 library. Steps of this project, Firstly I downloaded the dataset from Kaggle, and I will share with you the link of the dataset in this chapter. Then I visualized images of the dataset and reviewed XML format folders. Images tagged in xml format are not compatible for yolov7 so I converted xml files to txt format and saved the txt files in a file. And then I created a new dataset for yolov7 using text file and image files. I split the txt folder and the image folder into train, test and Val folders, as yolov7 wanted and I specified ways of these folders to yolov7 with \"data.yaml\". After I created to new dataset, I downloaded the yolov7 library and installed it. After I installed the yolov7 library I made to train with new dataset and I visualized the results. After the training, I detected masked and unmasked people in a picture I downloaded. I am currently on the way of improving myself. In this learning path, I would be very happy if you would examine my project and help me with how to improve my project or what I should do in this development path. I wish you a good day and good work.\n","\n","[For a detailed description of the dataset, please click here](https://www.kaggle.com/datasets/andrewmvd/face-mask-detection)\n","\n","Firstly, I made this project at the Google colab. If you want to look at the colab version, [click here.](https://colab.research.google.com/drive/1fcZqEgRgAE8neo-TG2QSdCuo0setQUvS?usp=sharing)"]},{"cell_type":"markdown","metadata":{},"source":["# Content <a id = \"cont\"></a>\n","- [Data Rewiew](#1)\n","- [Preparing DataSet](#2)\n","    - [Translate \".xml\" format to \".txt\" format](#2a)\n","    - [Create Dataset For Yolov7](#2b)\n","- [Yolov7](#3)\n","    - [Download Yolov7](#3a)\n","    - [Traning](#3b)\n","    - [Result Visualization](#3c)\n","    - [Detection](#3d)\n","- [CONCLUSION](#4)"]},{"cell_type":"markdown","metadata":{"id":"BvaCjEXt8es9"},"source":["# Data Rewiew <a id = \"1\"></a>\n","[Go Content](#cont)\n","\n","In this chapter, I reviewed the data in the dataset."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a4EA5Ntgjn-w"},"outputs":[],"source":["# I import libraries that I will use.\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","import matplotlib.pyplot as plt\n","\n","# For preparing\n","import xml.etree.cElementTree as ET\n","import glob\n","import os\n","import json\n","import random\n","import shutil\n","\n","from PIL import Image, ImageOps"]},{"cell_type":"markdown","metadata":{"id":"UZZhGq8SHedX"},"source":["XML file of the image labeled in XML format."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Aq97cRpj-I89","outputId":"8d1b992d-d81c-49f0-a205-b6a5d5fc6875"},"outputs":[],"source":["with open('/content/face-mask-detection/annotations/maksssksksss0.xml') as f:\n","    contents = f.read()\n","    print(contents)"]},{"cell_type":"markdown","metadata":{"id":"CP2SFYUMJfhx"},"source":["I visualized a few images in the dataset."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uoicM5haFlb3","outputId":"a85882d3-859d-4001-ad36-9d11f432a08d"},"outputs":[],"source":["Image.open(\"/content/face-mask-detection/images/maksssksksss0.png\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OUz7xV3eFsuK","outputId":"32b101e8-be48-4201-92d4-77a48ec843c1"},"outputs":[],"source":["Image.open(\"/content/face-mask-detection/images/maksssksksss1.png\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"afG97fFYFwqC","outputId":"02dc1e82-f323-479d-9d0a-fc5773e76abe"},"outputs":[],"source":["Image.open(\"/content/face-mask-detection/images/maksssksksss100.png\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6dit9w7QGJSj","outputId":"c3c5829e-226c-48d6-cd2e-ce1e03a5043e"},"outputs":[],"source":["# creating a image1 object\n","im1 = Image.open(r\"/content/face-mask-detection/images/maksssksksss100.png\")\n"," \n","# applying grayscale method\n","im2 = ImageOps.grayscale(im1)\n","\n","im2"]},{"cell_type":"markdown","metadata":{"id":"zFMvCZMthsN2"},"source":["# Preparing DataSet <a id = \"2\"></a>\n","[Go Content](#cont)\n","\n","In this chapter, I prepared the dataset for the yolov7."]},{"cell_type":"markdown","metadata":{"id":"UZU8N4ggixG6"},"source":["## Translate \".xml\" format to \".txt\" format <a id = \"2a\"></a>\n","[Go Content](#cont)\n","\n","Firstly, I translated xml format to txt format. While I made this work, I used this article If you want to check, [click here.](https://towardsdatascience.com/convert-pascal-voc-xml-to-yolo-for-object-detection-f969811ccba5)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CikwK_VPi3xe"},"outputs":[],"source":["def xml_to_yolo_bbox(bbox, w, h):\n","    # xmin, ymin, xmax, ymax\n","    x_center = ((bbox[2] + bbox[0]) / 2) / w\n","    y_center = ((bbox[3] + bbox[1]) / 2) / h\n","    \n","    width = (bbox[2] - bbox[0]) / w\n","    height = (bbox[3] - bbox[1]) / h\n","    \n","    return [x_center, y_center, width, height]\n","\n","def yolo_to_xml_bbox(bbox, w, h):\n","    # x_center, y_center, width, height\n","    w_half_len = (bbox[2] * w) / 2\n","    h_half_len = (bbox[3] * h) / 2\n","    \n","    xmin = int((bbox[0] * w) - w_half_len)\n","    ymin = int((bbox[1] * h) - h_half_len)\n","    xmax = int((bbox[0] * w) + w_half_len)\n","    ymax = int((bbox[1] * h) + h_half_len)\n","    \n","    return [xmin, ymin, xmax, ymax]\n","\n","classes = []\n","\n","input_dir = \"/content/face-mask-detection/annotations\"\n","output_dir = \"/content/labels\"\n","image_dir = \"/content/face-mask-detection/images\"\n","\n","os.mkdir(output_dir)\n","\n","if not os.path.isdir(output_dir):\n","    os.mkdir(output_dir)\n","\n","import glob\n","\n","files = glob.glob(os.path.join(input_dir, \"*.xml\"))\n","for fil in files:\n","    basename = os.path.basename(fil)\n","    filename = os.path.splitext(basename)[0]\n","    if not os.path.exists(os.path.join(image_dir, f\"{filename}.png\")):\n","        print(f\"{filename} image does not exist!\")\n","        continue\n","    \n","    result = []\n","    \n","    # Parse the content of the xml file\n","    tree = ET.parse(fil)\n","    root = tree.getroot()\n","    width = int(root.find(\"size\").find(\"width\").text)\n","    height = int(root.find(\"size\").find(\"height\").text)\n","    \n","    for obj in root.findall(\"object\"):\n","        label = obj.find(\"name\").text\n","        \n","        # check for new classes and append to list\n","        if label not in classes:\n","            classes.append(label)\n","        index = classes.index(label)\n","        pil_bbox = [int(x.text) for x in obj.find(\"bndbox\")]\n","        yolo_bbox = xml_to_yolo_bbox(pil_bbox, width, height)\n","        \n","        # convert data to string\n","        bbox_string = \" \".join([str(x) for x in yolo_bbox])\n","        result.append(f\"{index} {bbox_string}\")\n","    \n","    if result:\n","        # generate a yolo format text file for each xml file\n","        with open(os.path.join(output_dir, f\"{filename}.txt\"), \"w\", encoding = \"utf-8\") as f:\n","            f.write(\"\\n\".join(result))\n","# generate the classes file as reference\n","with open(\"/content/classes.txt\", \"w\", encoding = \"utf-8\") as f:\n","    f.write(json.dumps(classes))"]},{"cell_type":"markdown","metadata":{"id":"t1aHFhHeLkDe"},"source":["In the below code, I specified the classes of the dataset."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bnK3Xe98jtIQ","outputId":"b9f9786d-41c1-4864-fee2-72fa554c7fc0"},"outputs":[],"source":["with open('/content/classes.txt') as f:\n","    contents = f.read()\n","    print(contents)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qzbYT2YUlS5B","outputId":"f3902eec-2a91-4a8f-d15a-ec2ee1d278bb"},"outputs":[],"source":["Image.open(\"/content/face-mask-detection/images/maksssksksss0.png\")"]},{"cell_type":"markdown","metadata":{"id":"TMEgmolXMa_K"},"source":["xml format of the maksssksksss0 image"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xIF2sEX2kLV3","outputId":"02e0c925-c6db-4a16-c2e5-f759e55c052c"},"outputs":[],"source":["with open('/content/face-mask-detection/annotations/maksssksksss0.xml') as f:\n","    contents = f.read()\n","    print(contents)"]},{"cell_type":"markdown","metadata":{"id":"-xV8JfqGM1fY"},"source":["txt format of the maksssksksss0 image"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WzsBNl81kHbg","outputId":"eb41939a-b690-4f58-c388-2529d9027609"},"outputs":[],"source":["with open('/content/labels/maksssksksss0.txt') as f:\n","    contents = f.read()\n","    print(contents)"]},{"cell_type":"markdown","metadata":{"id":"ZO48AMjH7mek"},"source":["## Create Dataset For Yolov7 <a id = \"2b\"></a>\n","[Go Content](#cont)\n","\n","In this chapter, I created a dataset for yolov7."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IK6z1cJnkS7P"},"outputs":[],"source":["os.mkdir(\"/content/data/\")\n","os.mkdir('/content/data/train')\n","os.mkdir('/content/data/val')\n","os.mkdir('/content/data/test')\n","os.mkdir('/content/data/train/images')\n","os.mkdir('/content/data/train/labels')\n","os.mkdir('/content/data/test/images')\n","os.mkdir('/content/data/test/labels')\n","os.mkdir('/content/data/val/images')\n","os.mkdir('/content/data/val/labels')"]},{"cell_type":"markdown","metadata":{"id":"xreD-YMhNe4u"},"source":["In the below code, I added image names of in the dataset in the list. Because I used it when created the dataset. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s9IJuK16kuwY"},"outputs":[],"source":["metarial = []\n","\n","for i in os.listdir(\"/content/face-mask-detection/images\"):\n","    srt = i[:-4]\n","    metarial.append(srt)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IjXSCy4Ik6Am","outputId":"05418a40-d69c-41ac-e250-d497b800f79c"},"outputs":[],"source":["len(metarial)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3w7H3OGDk8jo","outputId":"86d3d6ee-5df0-4b1c-d28c-c39cfb662fc0"},"outputs":[],"source":["# a few image names of in the dataset\n","metarial[0:10]"]},{"cell_type":"markdown","metadata":{"id":"ReDEl8WEO_bd"},"source":["In the below code, Created function. Actually, I split the dataset into train, test and val."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5ofBf7SkksdJ"},"outputs":[],"source":["def preparinbdata(main_txt_file, main_img_file, train_size, test_size, val_size):\n","    \n","    for i in range(0,train_size):\n","        \n","        source_txt = main_txt_file + \"/\" + metarial[i] + \".txt\"\n","        source_img = main_img_file + \"/\" + metarial[i] + \".png\"\n","        \n","        mstring = metarial[i]\n","        train_destination_txt = \"/content/data/train/labels\" + \"/\" + metarial[i] + \".txt\" \n","        train_destination_png = \"/content/data/train/images\" + \"/\" + metarial[i] + \".png\" \n","                \n","        shutil.copy(source_txt, train_destination_txt)\n","        shutil.copy(source_img, train_destination_png)\n","                \n","        #metarial.remove(file_name[:-4])\n","                \n","                \n","    for l in range(train_size , train_size + test_size):\n","        \n","        source_txt = main_txt_file + \"/\" + metarial[l] + \".txt\"\n","        source_img = main_img_file + \"/\" + metarial[l] + \".png\"\n","        \n","        mstring = metarial[l]\n","        test_destination_txt = \"/content/data/test/labels\" + \"/\" + metarial[l] + \".txt\"\n","        test_destination_png = \"/content/data/test/images\" + \"/\" + metarial[l] + \".png\"\n","                \n","        shutil.copy(source_txt, test_destination_txt)\n","        shutil.copy(source_img, test_destination_png)\n","                \n","        #metarial.remove(file_name[:-4])\n","                \n","                \n","    for n in range(train_size + test_size , train_size + test_size + val_size):\n","        \n","        source_txt = main_txt_file + \"/\" + metarial[n] + \".txt\"\n","        source_img = main_img_file + \"/\" + metarial[n] + \".png\"\n","        \n","        mstring = metarial[n]\n","        val_destination_txt = \"/content/data/val/labels\" + \"/\" + metarial[n] + \".txt\"\n","        val_destination_png = \"/content/data/val/images\" + \"/\" + metarial[n] + \".png\"\n","                \n","        shutil.copy(source_txt, val_destination_txt)\n","        shutil.copy(source_img, val_destination_png)\n","                \n","        #metarial.remove(file_name[:-4])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nh77o46elMT5"},"outputs":[],"source":["preparinbdata(\"/content/labels\", \"/content/face-mask-detection/images\", 603, 150, 100)"]},{"cell_type":"markdown","metadata":{"id":"9SYKwcCPPkWg"},"source":["I created \".yaml\" folder."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZJQo8JVJl_yH","outputId":"d83946f4-e7d9-4870-c881-696a947bc106"},"outputs":[],"source":["# configure .yaml file to guide the model for training\n","%cd /content/data\n","\n","yaml_text = \"\"\"train: /content/data/train/images\n","val: /content/data/val/images\n","\n","nc: 3\n","names: [\"without_mask\", \"with_mask\", \"mask_weared_incorrect\"]\"\"\"\n","\n","with open(\"/content/data/data.yaml\", 'w') as file:\n","    file.write(yaml_text)\n","\n","%cat data/data.yaml"]},{"cell_type":"markdown","metadata":{"id":"DUcm-luhmPz6"},"source":["# Yolov7 <a id = \"3\"></a>\n","[Go Content](#cont)\n","\n","In this chapter, I used the yolov7."]},{"cell_type":"markdown","metadata":{"id":"rBLSv0DomTAd"},"source":["## Download Yolov7 <a id = \"3a\"></a>\n","[Go Content](#cont)\n","\n","In this chapter, I downloaded the yolov7 library and the pre-trained \".pt\" file."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YpnYvhqemaWo","outputId":"072bb153-94c3-4d22-ac4e-498d836a74a5"},"outputs":[],"source":["!# Download YOLOv7 code\n","%cd /content/\n","!git clone https://github.com/WongKinYiu/yolov7\n","%cd yolov7\n","!ls"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"13icCZJMmi2O","outputId":"715d3112-a13c-4dc3-e7e2-a23b7549c5f3"},"outputs":[],"source":["!# Download trained weights\n","!wget https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7.pt"]},{"cell_type":"markdown","metadata":{"id":"RozQyUep7y-d"},"source":["## Traning <a id = \"3b\"></a>\n","[Go Content](#cont)\n","\n","In this chapter, I made to train with yolov7 and the dataset."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AkU8_27KS57v","outputId":"56326de0-5112-4a3e-a3b3-c4b06c8eb68c"},"outputs":[],"source":["%cd /content/"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3t7-N5sZm04Y","outputId":"15e009a8-f7b0-431f-f2f6-935cd45ecaa8"},"outputs":[],"source":["# Train\n","!python /content/yolov7/train.py --workers 8 --device 0 --batch-size 16 --epochs 50 --data /content/data/data.yaml  --cfg /content/yolov7/cfg/training/yolov7.yaml --weights '' --name yolov7_1 --hyp /content/yolov7/data/hyp.scratch.p5.yaml"]},{"cell_type":"markdown","metadata":{"id":"klDiVtuK8Ew6"},"source":["## Result Visualization <a id = \"3c\"></a>\n","[Go Content](#cont)\n","\n","In this chapter, I visualized the training result of the yolov7."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KE-LI6TY8Lga","outputId":"ef372313-11c4-4c77-bb28-8c632fff8c11"},"outputs":[],"source":["Image.open(\"/content/runs/train/yolov7_1/results.png\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BUao04G1wGB3","outputId":"66d98f38-6b51-4d6d-9e35-708dbe19c0da"},"outputs":[],"source":["Image.open(\"/content/runs/train/yolov7_1/train_batch0.jpg\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x7FbNa3EwNkC","outputId":"c78a52e6-bfd5-42df-884e-b296034d8e8b"},"outputs":[],"source":["Image.open(\"/content/runs/train/yolov7_1/train_batch9.jpg\")"]},{"cell_type":"markdown","metadata":{"id":"-z96oS0f0loJ"},"source":["In the code below, I detected masked and unmasked people in the pictures in the test dataset."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Bw3MYYouxw9X","outputId":"a00e37c7-7c4e-4e9e-eaf5-24cd977187bf"},"outputs":[],"source":["!# Detection\n","!python /content/yolov7/detect.py --weights /content/runs/train/yolov7_1/weights/best.pt --conf 0.25 --img-size 640 --source /content/data/test/images/"]},{"cell_type":"markdown","metadata":{"id":"3yJrBFjL1f2V"},"source":["I visualized results of test detected."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NBMDYpXvx89V","outputId":"2ecdad38-9836-4bc8-920e-cc40bd598163"},"outputs":[],"source":["Image.open(\"/content/runs/detect/exp/maksssksksss1.png\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VaQMSBV4yFss","outputId":"4a8096b7-d2b9-46a3-8a75-ac8de65cfb89"},"outputs":[],"source":["Image.open(\"/content/runs/detect/exp/maksssksksss508.png\")"]},{"cell_type":"markdown","metadata":{"id":"8bdcwNtK73hz"},"source":["## Detection <a id = \"3d\"></a>\n","[Go Content](#cont)\n","\n","In this part, I detected the masked and unmasked people in a random photo I downloaded from the internet with the yolov7 library."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pp6X4b4Px0tq","outputId":"251450ae-d676-4b2c-fefc-a88cd260e607"},"outputs":[],"source":["# I downloaded one image for use at the detect.\n","%cd /content\n","!wget \"https://onecms-res.cloudinary.com/image/upload/s--XV7DHKzY--/c_fill,g_auto,h_468,w_830/f_auto,q_auto/people-wearing-mask-at-orchard-road-singapore-feb-3--49-.jpg?itok=GdDk1T6A\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ezE4O0LPxxeF","outputId":"76a8a236-f114-4dfc-fc75-cd28ae38f747"},"outputs":[],"source":["!# Detection\n","!python /content/yolov7/detect.py --weights /content/runs/train/yolov7_1/weights/best.pt --conf 0.25 --img-size 640 --source /content/image0.jpg"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gjkmLMq-yoLZ","outputId":"c87a462b-9d15-489a-95a9-0e9d4a7dde7b"},"outputs":[],"source":["Image.open(\"/content/runs/detect/exp3/image0.jpg\")"]},{"cell_type":"markdown","metadata":{"id":"c9Ke0MF9zuEy"},"source":["# CONCLUSION <a id = \"4\"></a>\n","[Go Content](#cont)"]},{"cell_type":"markdown","metadata":{"id":"RIQx1NgXzwZT"},"source":["In this my work, I worked on yolov7 library. In the future, I will continue to make computer vision projects similar to this project. I am learning the English language newly if I make an errata please advise me in the comment. Thank you for reading my notebook, your votes and your comments. I will be waiting for your advice."]}],"metadata":{"kernelspec":{"display_name":"Python 3.10.6 ('proton')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"},"vscode":{"interpreter":{"hash":"ae1f3d19af4a627e6fd227f47e41f2bdb26008c49e5df6c5bb5291576095ff68"}}},"nbformat":4,"nbformat_minor":4}
